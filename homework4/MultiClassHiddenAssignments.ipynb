{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Team Members\n",
        "1. AXB210119\tAbhinava Bharamasagara Nanjundaiah\n",
        "2. HXD220007\tHarsha Priya Daggubati\n",
        "3. PXP210104\tPritika Priyadarshini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX2h3CzmMytT",
        "outputId": "1074ac6b-314f-4ec1-b87d-dffcfec809fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'VEC' already exists and is not an empty directory.\n",
            "/home/abhinava/VEC\n",
            "Requirement already satisfied: igraph in /home/abhinava/.local/lib/python3.8/site-packages (0.10.2)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /home/abhinava/.local/lib/python3.8/site-packages (from igraph) (1.6.4)\n",
            "Requirement already satisfied: Cython in /home/abhinava/.local/lib/python3.8/site-packages (0.29.32)\n",
            "Processing /home/abhinava/VEC\n",
            "Building wheels for collected packages: TPM\n",
            "  Building wheel for TPM (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for TPM: filename=TPM-0.0.0-cp38-cp38-linux_x86_64.whl size=2755801 sha256=fc383dd29a902b20b25dc2c69cd60cd7e592d690605d0225dc8c2f5fd5d4651d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xou7i1_w/wheels/44/34/0d/41a430ec86534abcc318b33aa547d7cc734f7be087dcf3badc\n",
            "Successfully built TPM\n",
            "Installing collected packages: TPM\n",
            "  Attempting uninstall: TPM\n",
            "    Found existing installation: TPM 0.0.0\n",
            "    Uninstalling TPM-0.0.0:\n",
            "      Successfully uninstalled TPM-0.0.0\n",
            "Successfully installed TPM-0.0.0\n",
            "/home\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vkomaragiri/VEC.git\n",
        "%cd ./VEC/\n",
        "!pip install igraph\n",
        "!pip install Cython\n",
        "!pip install .\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ov7DQ7VAQH8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from MN import MN \n",
        "from BTP import BTP\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C58D0B7MQabB"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "    def __init__(self, fpath):\n",
        "\n",
        "        f = open(fpath, \"r\")\n",
        "\n",
        "        self.nvars = int(f.readline())  # 1\n",
        "\n",
        "        line = np.asarray(f.readline().split(), dtype=np.int32)  # 2\n",
        "        self.evid_var_ids = line[1:]\n",
        "        evid_indices = range(1, self.evid_var_ids.shape[0]*2, 2)\n",
        "\n",
        "        line = np.asarray(f.readline().split(), dtype=np.int32)  # 3\n",
        "        self.query_var_ids = line[1:]\n",
        "        query_indices = range(\n",
        "            self.evid_var_ids.shape[0]*2+1, (self.evid_var_ids.shape[0]+self.query_var_ids.shape[0])*2, 2)\n",
        "\n",
        "        line = np.asarray(f.readline().split(), dtype=np.int32)  # 4\n",
        "        self.hidden_var_ids = line[1:]\n",
        "\n",
        "        line = f.readline()  # 5\n",
        "        self.nproblems = int(f.readline())  # 6\n",
        "\n",
        "        self.evid_assignments = []\n",
        "        self.query_assignments = []\n",
        "        self.weights = []\n",
        "        for i in range(self.nproblems):\n",
        "            line = np.asarray(f.readline().split(), dtype=float)\n",
        "            self.evid_assignments.append(np.asarray(\n",
        "                line[evid_indices], dtype=np.int32))\n",
        "            self.query_assignments.append(np.asarray(\n",
        "                line[query_indices], dtype=np.int32))\n",
        "            self.weights.append(line[-1])\n",
        "        self.evid_assignments = np.asarray(self.evid_assignments)\n",
        "        self.query_assignments = np.asarray(self.query_assignments)\n",
        "        self.weights = np.asarray(self.weights)\n",
        "        self.hidden_assignments = []\n",
        "\n",
        "    def convertToXYWithH(self, hidden_assignments):\n",
        "        return (np.concatenate((self.evid_assignments, hidden_assignments), axis=1), self.query_assignments)\n",
        "\n",
        "    def convertToXY(self):\n",
        "        return (self.evid_assignments, self.query_assignments)\n",
        "\n",
        "    def convertResults(self, query_predictions, removed_qvars):\n",
        "        self.query_var_ids = np.delete(self.query_var_ids, removed_qvars)\n",
        "        out = np.zeros(\n",
        "            (query_predictions.shape[0], 1+2*self.query_var_ids.shape[0]), dtype=int)\n",
        "        out[:, 2::2] = query_predictions[:, :]\n",
        "        out[:, 1::2] = self.query_var_ids\n",
        "        out[:, 0] = self.query_var_ids.shape[0]\n",
        "        return out\n",
        "\n",
        "    def computeLogProb(self, mn, order, X, y):\n",
        "        out = np.zeros(X.shape[0])\n",
        "        for i in range(X.shape[0]):\n",
        "            for j in range(len(self.evid_var_ids)):\n",
        "                mn.setEvidence(self.evid_var_ids[j], X[i][j])\n",
        "            for j in range(y.shape[1]):\n",
        "                mn.setEvidence(self.query_var_ids[j], y[i][j])\n",
        "            btp = BTP(mn, order)\n",
        "            out[i] = np.log10(btp.getPR())\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def computeErr(true_ll, pred_ll):\n",
        "        return np.sum(true_ll)-np.sum(pred_ll)\n",
        "\n",
        "    @staticmethod\n",
        "    def computeScore(err, max_err):\n",
        "        return np.max((0, 100*(1.0-err/max_err)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3L0CyahRQeVU"
      },
      "outputs": [],
      "source": [
        "data_directory = './content/MLC/'\n",
        "dname = 'Sample_1_MLC_2022'\n",
        "data = Data(data_directory+dname+'.data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h9sNUKtGUVjJ"
      },
      "outputs": [],
      "source": [
        "X, y = data.convertToXY()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mqYoMNT5UXq_"
      },
      "outputs": [],
      "source": [
        "load_order = np.loadtxt(data_directory+dname+'.order',\n",
        "                        dtype=np.int32, delimiter=' ').astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8duoIxVlUa_y"
      },
      "outputs": [],
      "source": [
        "def generate_features(ev_id, ev_ass, q_id, q_ass):\n",
        "    mn = MN()\n",
        "    mn.read(data_directory+dname+'.uai')\n",
        "    for j in range(len(ev_id)):\n",
        "        mn.setEvidence(ev_id[j], ev_ass[j])\n",
        "    for j in range(len(q_id)):\n",
        "        mn.setEvidence(q_id[j], q_ass[j])\n",
        "\n",
        "    btp = BTP(mn, load_order)\n",
        "    btp.performUpwardPass()\n",
        "\n",
        "    store_all = {}\n",
        "    # storing reversed order only\n",
        "    for i, bucket in enumerate(reversed(btp.buckets)):\n",
        "        # don't care about empty bucket\n",
        "        if len(bucket) == 0:\n",
        "            continue\n",
        "        for func in bucket:\n",
        "            # loading in reversed order, since buckets are stored in order\n",
        "            bucket_id = btp.order[len(btp.buckets) - i - 1]\n",
        "            # can also get bucket_id from most id occurrence in that bucket (not concrete but i tried this first)\n",
        "            # bucket_id = max(set(func.getVarIDs()), key=lambda x: list(func.getVarIDs()).count(x))\n",
        "            store_all.setdefault(bucket_id, [])\n",
        "            min_order = []\n",
        "            # seeing all the id's\n",
        "            for id in func.getVarIDs():\n",
        "                min_order.append([list(btp.order).index(id), id])\n",
        "            # irrespective of it contains bucket_id, we are placing at the minimum order\n",
        "            # coz if not we will be missing an hidden assignment\n",
        "            mini = min(min_order, key=lambda x: x[0])\n",
        "            store_all.setdefault(mini[1], [])\n",
        "            store_all[mini[1]].append(func)\n",
        "    hidden_assignments = {}\n",
        "    for key in reversed(btp.order):\n",
        "        if store_all.get(key) == None:\n",
        "            # its either query or evidence\n",
        "            continue\n",
        "        if len(store_all[key]) == 0:\n",
        "            assert (\"should not come here\")\n",
        "        # print(key)\n",
        "        max_val_0 = []\n",
        "        max_val_1 = []\n",
        "        for func in store_all[key]:\n",
        "            if len(func.getVarIDs()) > 1:\n",
        "                solved_func = func.instantiateEvid()\n",
        "                max_val_0.append(solved_func.getPotential()[0])\n",
        "                max_val_1.append(solved_func.getPotential()[1])\n",
        "            else:\n",
        "                max_val_0.append(func.getPotential()[0])\n",
        "                max_val_1.append(func.getPotential()[1])\n",
        "\n",
        "        m0 = max(max_val_0)\n",
        "        m1 = max(max_val_1)\n",
        "\n",
        "        hidden_assignments[key] = 1 if m1 > m0 else 0\n",
        "        mn.setEvidence(key, hidden_assignments[key])\n",
        "\n",
        "    new_features = [0] * len(hidden_assignments)\n",
        "    for key in hidden_assignments:\n",
        "        new_features[list(data.hidden_var_ids).index(key)\n",
        "                     ] = hidden_assignments[key]\n",
        "    return new_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDPcN_GeUcz1",
        "outputId": "e16cff76-9531-4cce-9203-e4d9c56b2803"
      },
      "outputs": [],
      "source": [
        "data_set = np.zeros((data.nproblems, len(\n",
        "    data.hidden_var_ids)))\n",
        "start = time.time()\n",
        "for index in range(data.evid_assignments.shape[0]):\n",
        "    each = time.time()\n",
        "    hidden_assignments = generate_features(\n",
        "        data.evid_var_ids, data.evid_assignments[index], data.query_var_ids, data.query_assignments[index])\n",
        "\n",
        "    data_set[index][:] = hidden_assignments\n",
        "    if index % 500 == 0:\n",
        "        np.savetxt(X=data_set, delimiter=' ', fmt='%d',\n",
        "                   fname=data_directory+dname+'.new_features')\n",
        "    print(index, \"Done in \", time.time() - each)\n",
        "np.savetxt(X=data_set, delimiter=' ', fmt='%d',\n",
        "           fname=data_directory+dname+'.new_features')\n",
        "print(\"Total Time: \", time.time() - start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
