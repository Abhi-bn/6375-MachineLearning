{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X27UOUsKHaX-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from joblib import Parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jlzg0pAjHtG0"
      },
      "outputs": [],
      "source": [
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1K6r-gwXHup-"
      },
      "outputs": [],
      "source": [
        "# rescale the data, use the traditional train/test split\n",
        "# (60K: Train) and (10K: Test)\n",
        "X_train, X_test = X[:60000], X[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veZPlCbEIQTI"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "### hidden_layer_sizes (3 parameters)\n",
        "#### The ith element represents the number of neurons in the ith hidden layer.\n",
        "1. n_neighbors = 3\n",
        "2. n_neighbors = 5\n",
        "3. n_neighbors = 7\n",
        "\n",
        "### Activation function for the hidden layer.\n",
        "‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
        "‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
        "‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
        "‘relu’, the rectified linear unit function, returns f(x) = max(0, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecWf2wOho8Bf",
        "outputId": "eaf6f28d-a828-427b-ab20-a8048c3d72a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02100000000000002\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='relu', solver='adam', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LVLKQFqo3o",
        "outputId": "7f4994a8-e791-47f5-a8bc-cf94b9b8c1bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.029000000000000026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='relu', solver='sgd', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir1axs5iq1eB",
        "outputId": "0a3d54b0-80dd-45bc-9f3a-2d26213ed6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0252\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='relu', solver='lbfgs', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk07Ja_stpmz",
        "outputId": "96f98a02-4fde-49e5-9183-5b3cd2b2b669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07779999999999998\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='identity', solver='adam', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE0UY38ItsRF",
        "outputId": "ec203cd7-34ac-43df-fa56-0b37011f40c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.022399999999999975\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='logistic', solver='adam', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyCRQvqRxD9N",
        "outputId": "697fa7ea-6964-4832-b2e1-fa389575d9f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.020299999999999985\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='tanh', solver='adam', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU97nyZQxLWr",
        "outputId": "848e00b5-829c-4a5f-da31-1f92747bd49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.03320000000000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='tanh', solver='sgd', learning_rate='adaptive', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2yyzRK60dmZ",
        "outputId": "334e25fb-4242-41ad-e88a-09073bc56abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.021199999999999997\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='relu', solver='adam', learning_rate='adaptive', learning_rate_init=0.001, max_iter=500)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH1SJG4O1eFp",
        "outputId": "e4886625-a613-4dff-9402-867c129076c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.02180000000000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='relu', solver='sgd', learning_rate='adaptive', learning_rate_init=0.001, max_iter=500)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U-Ajr7SCDd0",
        "outputId": "c79f07a5-62a1-495b-c711-c0dc3d03e3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.021599999999999953\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='tanh', solver='adam', learning_rate='adaptive', learning_rate_init=0.001, max_iter=500)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JDCh69UCvMM",
        "outputId": "6c3a002d-95e2-4f27-d7fc-ee51f5d0e025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.06440000000000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='logistic', solver='sgd', learning_rate='adaptive', learning_rate_init=0.001, max_iter=200)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOx9E0WfC1Ny",
        "outputId": "3d6b3332-45f6-4c3c-babb-b29e7c4cf989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.028699999999999948\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='logistic', solver='lbfgs', learning_rate='adaptive', learning_rate_init=0.001, max_iter=200)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQmy7oq-C4ru",
        "outputId": "f7623505-d158-4699-8181-bb3dd8d0f444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07509999999999994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='identity', solver='lbfgs', learning_rate='adaptive', learning_rate_init=0.001, max_iter=200)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHtT7RZHC5Q1",
        "outputId": "45c15f6e-f32f-4460-9ca1-7f33b5d7dea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07469999999999999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='identity', solver='sgd', learning_rate='adaptive', learning_rate_init=0.001, max_iter=200)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye2RJZwYHZ9b",
        "outputId": "bb4ca75a-cec9-460d-cd4a-871b4ed45fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.021399999999999975\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='tanh', solver='adam', learning_rate='constant', learning_rate_init=0.001)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9n-YGrDHZxl",
        "outputId": "e2954015-10c8-4c28-a692-514e8eb4ce61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.021100000000000008\n"
          ]
        }
      ],
      "source": [
        "# Doing each parameters in single code block just in case I screw something up\n",
        "mlpclassifier = MLPClassifier(activation='tanh', solver='adam', learning_rate='constant', learning_rate_init=0.0001, max_iter=500)\n",
        "mlpclassifier.fit(X_train, y_train)\n",
        "print(1.0 - mlpclassifier.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYy_ZmKAHZo6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
